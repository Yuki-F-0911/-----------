#!/usr/bin/env python3
"""
ãƒ¬ãƒ“ãƒ¥ãƒ¼åé›†ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ±åˆã—ã¦å®Ÿè¡Œ

ä½¿ç”¨æ–¹æ³•:
    python main.py --help
    python main.py shoes --list
    python main.py shoes --add "Nike" "Pegasus 41"
    python main.py collect --shoe-id <id> --source youtube
    python main.py collect-all --limit 10
"""

import argparse
import json
import sys
from datetime import datetime
from typing import List, Optional

# åŒä¸€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import check_config, POPULAR_MODELS, SERPER_API_KEY
from shoe_finder import find_trending_shoes, get_shoes_from_predefined_list, ShoeInfo
from youtube_collector import search_shoe_reviews, search_running_shoe_reviews, YouTubeVideo
from web_collector import search_shoe_reviews_social, SocialPost  # Webæ¤œç´¢ãƒ™ãƒ¼ã‚¹ï¼ˆAPIä¸è¦ï¼‰
from db_handler import (
    get_all_shoes,
    get_shoe_by_brand_model,
    create_shoe,
    ensure_shoe_exists,
    create_curated_source,
    get_curated_sources_for_shoe,
    get_stats,
    test_connection,
)


def cmd_config(args):
    """è¨­å®šçŠ¶æ³ã‚’è¡¨ç¤º"""
    print('=== è¨­å®šçŠ¶æ³ ===\n')
    status = check_config()
    for key, value in status.items():
        emoji = 'âœ…' if value else 'âŒ'
        print(f'{emoji} {key}: {"è¨­å®šæ¸ˆã¿" if value else "æœªè¨­å®š"}')
    
    print('\n=== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ ===')
    if test_connection():
        stats = get_stats()
        for key, value in stats.items():
            print(f'   {key}: {value}')
    else:
        print('   âŒ æ¥ç¶šå¤±æ•—')


def cmd_shoes_list(args):
    """ã‚·ãƒ¥ãƒ¼ã‚ºä¸€è¦§ã‚’è¡¨ç¤º"""
    print('=== ç™»éŒ²æ¸ˆã¿ã‚·ãƒ¥ãƒ¼ã‚º ===\n')
    shoes = get_all_shoes()
    
    if not shoes:
        print('ã‚·ãƒ¥ãƒ¼ã‚ºãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“')
        return

    for shoe in shoes:
        print(f'ğŸ“¦ {shoe["brand"]} {shoe["modelName"]}')
        print(f'   ID: {shoe["id"]}')
        print(f'   ã‚«ãƒ†ã‚´ãƒª: {shoe["category"]}')
        if shoe.get('releaseYear'):
            print(f'   ç™ºå£²å¹´: {shoe["releaseYear"]}')
        print()


def cmd_shoes_add(args):
    """ã‚·ãƒ¥ãƒ¼ã‚ºã‚’è¿½åŠ """
    brand = args.brand
    model_name = args.model
    category = args.category or 'ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°'

    print(f'ğŸ“¦ ã‚·ãƒ¥ãƒ¼ã‚ºã‚’è¿½åŠ : {brand} {model_name}')
    
    existing = get_shoe_by_brand_model(brand, model_name)
    if existing:
        print(f'âš ï¸ æ—¢ã«å­˜åœ¨ã—ã¾ã™ (ID: {existing["id"]})')
        return

    shoe_id = create_shoe(brand, model_name, category)
    if shoe_id:
        print(f'âœ… è¿½åŠ å®Œäº† (ID: {shoe_id})')
    else:
        print('âŒ è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ')


def cmd_shoes_import(args):
    """äº‹å‰å®šç¾©ãƒªã‚¹ãƒˆã‹ã‚‰ã‚·ãƒ¥ãƒ¼ã‚ºã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    print('=== ã‚·ãƒ¥ãƒ¼ã‚ºã‚¤ãƒ³ãƒãƒ¼ãƒˆ ===\n')
    
    shoes = get_shoes_from_predefined_list()
    added = 0
    skipped = 0

    for shoe in shoes:
        shoe_id = ensure_shoe_exists(shoe.brand, shoe.model_name)
        if shoe_id:
            existing = get_shoe_by_brand_model(shoe.brand, shoe.model_name)
            if existing and existing['id'] == shoe_id:
                print(f'âœ… {shoe.brand} {shoe.model_name}')
                added += 1
            else:
                print(f'â­ï¸ {shoe.brand} {shoe.model_name} (æ—¢å­˜)')
                skipped += 1
        else:
            print(f'âŒ {shoe.brand} {shoe.model_name}')

    print(f'\nå®Œäº†: è¿½åŠ  {added} ä»¶, ã‚¹ã‚­ãƒƒãƒ— {skipped} ä»¶')


def cmd_collect(args):
    """ç‰¹å®šã®ã‚·ãƒ¥ãƒ¼ã‚ºã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åé›†"""
    shoe_id = args.shoe_id
    sources = args.sources.split(',') if args.sources else ['youtube', 'social']

    # ã‚·ãƒ¥ãƒ¼ã‚ºæƒ…å ±ã‚’å–å¾—
    shoes = get_all_shoes()
    shoe = next((s for s in shoes if s['id'] == shoe_id), None)
    
    if not shoe:
        print(f'âŒ ã‚·ãƒ¥ãƒ¼ã‚ºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {shoe_id}')
        return

    brand = shoe['brand']
    model_name = shoe['modelName']
    print(f'=== ãƒ¬ãƒ“ãƒ¥ãƒ¼åé›†: {brand} {model_name} ===\n')

    total_collected = 0

    # YouTube
    if 'youtube' in sources:
        print('ğŸ¬ YouTubeæ¤œç´¢ä¸­...')
        videos = search_shoe_reviews(brand, model_name, max_results=10)
        for video in videos:
            source_id = create_curated_source(
                shoe_id=shoe_id,
                source_type='VIDEO',
                platform='youtube.com',
                title=video.title,
                url=video.url,
                author=video.channel_name,
                excerpt=video.description[:200] if video.description else None,
                thumbnail_url=video.thumbnail_url,
                reliability=0.8,
                metadata={
                    'video_id': video.video_id,
                    'view_count': video.view_count,
                    'like_count': video.like_count,
                    'published_at': video.published_at,
                },
            )
            if source_id:
                print(f'   âœ… {video.title[:50]}...')
                total_collected += 1
        print(f'   YouTube: {len(videos)} ä»¶å–å¾—\n')

    # Social (Twitter/X + Reddit via Webæ¤œç´¢ - APIä¸è¦)
    if 'social' in sources and SERPER_API_KEY:
        social_results = search_shoe_reviews_social(brand, model_name, max_results=10)
        
        # Twitter/X
        twitter_posts = social_results.get('twitter', [])
        for post in twitter_posts:
            source_id = create_curated_source(
                shoe_id=shoe_id,
                source_type='SNS',
                platform='twitter.com',
                title=post.title,
                url=post.url,
                author=post.author,
                excerpt=post.snippet[:200] if post.snippet else None,
                reliability=0.65,
            )
            if source_id:
                print(f'   âœ… ğŸ¦ {post.author}: {post.title[:40]}...')
                total_collected += 1
        print(f'   X (Twitter): {len(twitter_posts)} ä»¶å–å¾—')

        # Reddit
        reddit_posts = social_results.get('reddit', [])
        for post in reddit_posts:
            source_id = create_curated_source(
                shoe_id=shoe_id,
                source_type='COMMUNITY',
                platform='reddit.com',
                title=post.title,
                url=post.url,
                author=post.author,
                excerpt=post.snippet[:200] if post.snippet else None,
                reliability=0.6,
            )
            if source_id:
                print(f'   âœ… ğŸ“ {post.author}: {post.title[:40]}...')
                total_collected += 1
        print(f'   Reddit: {len(reddit_posts)} ä»¶å–å¾—\n')
    elif 'social' in sources:
        print('âš ï¸ SERPER_API_KEYãŒæœªè¨­å®šã®ãŸã‚ã‚½ãƒ¼ã‚·ãƒ£ãƒ«æ¤œç´¢ã‚’ã‚¹ã‚­ãƒƒãƒ—\n')

    print(f'=== å®Œäº†: åˆè¨ˆ {total_collected} ä»¶ç™»éŒ² ===')


def cmd_collect_all(args):
    """å…¨ã‚·ãƒ¥ãƒ¼ã‚ºã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åé›†"""
    limit = args.limit or 5
    sources = args.sources.split(',') if args.sources else ['youtube']

    print('=== å…¨ã‚·ãƒ¥ãƒ¼ã‚ºã®ãƒ¬ãƒ“ãƒ¥ãƒ¼åé›† ===\n')
    
    shoes = get_all_shoes()
    if not shoes:
        print('ã‚·ãƒ¥ãƒ¼ã‚ºãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã« shoes import ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚')
        return

    shoes_to_process = shoes[:limit]
    print(f'{len(shoes_to_process)} ä»¶ã®ã‚·ãƒ¥ãƒ¼ã‚ºã‚’å‡¦ç†ã—ã¾ã™\n')

    for i, shoe in enumerate(shoes_to_process, 1):
        print(f'[{i}/{len(shoes_to_process)}] {shoe["brand"]} {shoe["modelName"]}')
        
        # YouTube
        if 'youtube' in sources:
            videos = search_shoe_reviews(shoe['brand'], shoe['modelName'], max_results=5)
            for video in videos:
                create_curated_source(
                    shoe_id=shoe['id'],
                    source_type='VIDEO',
                    platform='youtube.com',
                    title=video.title,
                    url=video.url,
                    author=video.channel_name,
                    thumbnail_url=video.thumbnail_url,
                    reliability=0.8,
                    metadata={'video_id': video.video_id},
                )
            print(f'   YouTube: {len(videos)} ä»¶')

        # Social (Webæ¤œç´¢ãƒ™ãƒ¼ã‚¹ - APIä¸è¦)
        if 'social' in sources and SERPER_API_KEY:
            social_results = search_shoe_reviews_social(
                shoe['brand'], shoe['modelName'], max_results=5
            )
            
            twitter_count = 0
            for post in social_results.get('twitter', []):
                if create_curated_source(
                    shoe_id=shoe['id'],
                    source_type='SNS',
                    platform='twitter.com',
                    title=post.title,
                    url=post.url,
                    author=post.author,
                    reliability=0.65,
                ):
                    twitter_count += 1
            print(f'   X (Twitter): {twitter_count} ä»¶')
            
            reddit_count = 0
            for post in social_results.get('reddit', []):
                if create_curated_source(
                    shoe_id=shoe['id'],
                    source_type='COMMUNITY',
                    platform='reddit.com',
                    title=post.title,
                    url=post.url,
                    author=post.author,
                    reliability=0.6,
                ):
                    reddit_count += 1
            print(f'   Reddit: {reddit_count} ä»¶')

        print()

    print('=== å®Œäº† ===')


def cmd_sources(args):
    """ã‚·ãƒ¥ãƒ¼ã‚ºã®ã‚½ãƒ¼ã‚¹ã‚’è¡¨ç¤º"""
    shoe_id = args.shoe_id
    
    # ã‚·ãƒ¥ãƒ¼ã‚ºæƒ…å ±ã‚’å–å¾—
    shoes = get_all_shoes()
    shoe = next((s for s in shoes if s['id'] == shoe_id), None)
    
    if not shoe:
        print(f'âŒ ã‚·ãƒ¥ãƒ¼ã‚ºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {shoe_id}')
        return

    print(f'=== {shoe["brand"]} {shoe["modelName"]} ã®ã‚½ãƒ¼ã‚¹ ===\n')
    
    sources = get_curated_sources_for_shoe(shoe_id)
    
    if not sources:
        print('ã‚½ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“')
        return

    for source in sources:
        emoji = {
            'VIDEO': 'ğŸ¬',
            'ARTICLE': 'ğŸ“„',
            'SNS': 'ğŸ¦',
            'COMMUNITY': 'ğŸ“',
            'MARKETPLACE': 'ğŸ›’',
            'OFFICIAL': 'ğŸ¢',
        }.get(source['type'], 'ğŸ“Œ')
        
        print(f'{emoji} [{source["type"]}] {source["title"][:60]}')
        print(f'   ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {source["platform"]}')
        print(f'   ä¿¡é ¼åº¦: {source["reliability"]}')
        print(f'   URL: {source["url"]}')
        print()


def main():
    parser = argparse.ArgumentParser(description='ãƒ¬ãƒ“ãƒ¥ãƒ¼åé›†ãƒ„ãƒ¼ãƒ«')
    subparsers = parser.add_subparsers(dest='command', help='ã‚³ãƒãƒ³ãƒ‰')

    # config ã‚³ãƒãƒ³ãƒ‰
    parser_config = subparsers.add_parser('config', help='è¨­å®šçŠ¶æ³ã‚’è¡¨ç¤º')
    parser_config.set_defaults(func=cmd_config)

    # shoes ã‚³ãƒãƒ³ãƒ‰
    parser_shoes = subparsers.add_parser('shoes', help='ã‚·ãƒ¥ãƒ¼ã‚ºç®¡ç†')
    shoes_subparsers = parser_shoes.add_subparsers(dest='shoes_command')
    
    # shoes list
    parser_shoes_list = shoes_subparsers.add_parser('list', help='ä¸€è¦§è¡¨ç¤º')
    parser_shoes_list.set_defaults(func=cmd_shoes_list)
    
    # shoes add
    parser_shoes_add = shoes_subparsers.add_parser('add', help='è¿½åŠ ')
    parser_shoes_add.add_argument('brand', help='ãƒ–ãƒ©ãƒ³ãƒ‰å')
    parser_shoes_add.add_argument('model', help='ãƒ¢ãƒ‡ãƒ«å')
    parser_shoes_add.add_argument('--category', '-c', help='ã‚«ãƒ†ã‚´ãƒª')
    parser_shoes_add.set_defaults(func=cmd_shoes_add)
    
    # shoes import
    parser_shoes_import = shoes_subparsers.add_parser('import', help='äº‹å‰å®šç¾©ãƒªã‚¹ãƒˆã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ')
    parser_shoes_import.set_defaults(func=cmd_shoes_import)

    # collect ã‚³ãƒãƒ³ãƒ‰
    parser_collect = subparsers.add_parser('collect', help='ç‰¹å®šã‚·ãƒ¥ãƒ¼ã‚ºã®ãƒ¬ãƒ“ãƒ¥ãƒ¼åé›†')
    parser_collect.add_argument('shoe_id', help='ã‚·ãƒ¥ãƒ¼ã‚ºID')
    parser_collect.add_argument('--sources', '-s', help='ã‚½ãƒ¼ã‚¹ (youtube,social) â€»socialã¯X+Reddit', default='youtube,social')
    parser_collect.set_defaults(func=cmd_collect)

    # collect-all ã‚³ãƒãƒ³ãƒ‰
    parser_collect_all = subparsers.add_parser('collect-all', help='å…¨ã‚·ãƒ¥ãƒ¼ã‚ºã®ãƒ¬ãƒ“ãƒ¥ãƒ¼åé›†')
    parser_collect_all.add_argument('--limit', '-l', type=int, help='å‡¦ç†ã™ã‚‹ã‚·ãƒ¥ãƒ¼ã‚ºæ•°', default=5)
    parser_collect_all.add_argument('--sources', '-s', help='ã‚½ãƒ¼ã‚¹ (youtube,social)', default='youtube')
    parser_collect_all.set_defaults(func=cmd_collect_all)

    # sources ã‚³ãƒãƒ³ãƒ‰
    parser_sources = subparsers.add_parser('sources', help='ã‚·ãƒ¥ãƒ¼ã‚ºã®ã‚½ãƒ¼ã‚¹ã‚’è¡¨ç¤º')
    parser_sources.add_argument('shoe_id', help='ã‚·ãƒ¥ãƒ¼ã‚ºID')
    parser_sources.set_defaults(func=cmd_sources)

    args = parser.parse_args()

    if hasattr(args, 'func'):
        args.func(args)
    else:
        parser.print_help()


if __name__ == '__main__':
    main()

